library(dplyr)
library(tidyverse)
library(lubridate)
# Visualization
library(ggplot2)
library(waterfalls)
library(plotly)
install.packages("finstr")
githubinstall::githubinstall("finstr")
df <- read.table(textConnection("1|a,b,c\n2|a,c\n3|b,d\n4|e,f"), header = F, sep = "|", stringsAsFactors = F)
View(df)
s <- strsplit(df$V2, split = ",")
s
data.frame(V1 = rep(df$V1, sapply(s, length)), V2 = unlist(s))
separate_rows(df, V2) in tidyr
library(tidyr)
separate_rows(df, V2)
rep(c("A","B","C","D","E")
)
df1 <- data.frame(first = rep(c("A","B","C","D","E")), second = rep(c(1,2),each=5),
third = rnorm(10))
View(df1)
dcast(df1, first ~ second, value.var="third")
?decast
?dcast
df = matrix(nrow = 3,ncol = 3)
df = data.frame(df)
View(df)
View(df)
df = data.frame(df)
View(df)
system("R CMD SHLIB calc_tstat.c")
df = matrix(nrow = 3,ncol = 3)
library(plyr)
alply(df,1)
library(AUC)
data(churn)
test_roc = roc(churn$predictions,churn$labels)
test_auc = auc(test_roc)
churn$predictions
rstudioapi::getActiveDocumentContext()$path
dirname(rstudioapi::getActiveDocumentContext()$path)
?rstudioapi::getActiveDocumentContext
getSourceEditorContext()
library(rstudioapi)
temp = dirname(rstudioapi::getActiveDocumentContext()$path)
temp
getConsoleEditorContext(rstudioaps)
getConsoleEditorContext()
getActiveDocumentContext()
getSourceEditorContext()
getSrcDirectory(getGeoData)
library(data.table)
library(data.cube)
install.packages("data.cube")
library(githubinstall)
githubinstall("data.cube")
install.packages("rpivotTable")
set.seed(1L)
ar.dimnames = list(color = sort(c("green","yellow","red")),
year = as.character(2011:2015),
status = sort(c("active","inactive","archived","removed")))
ar.dim = sapply(ar.dimnames, length)
ar.dim
sample(c(rep(NA, 4), 4:7/2), prod(ar.dim), TRUE)
c(rep(NA, 4), 4:7/2)
prod(ar.dim)
ar = array(sample(c(rep(NA, 4), 4:7/2), prod(ar.dim), TRUE),
unname(ar.dim),
ar.dimnames)
ar
cb = as.cube(ar)
library(data.cube)
library(rpivotTable)
cb = as.cube(ar)
print(cb)
str(cb)
all.equal(ar, as.array(cb))
all.equal(dim(ar), dim(cb))
all.equal(dimnames(ar), dimnames(cb))
arr = ar["green",,]
print(arr)
r = cb["green",]
print(r)
arr = ar["green",,,drop=FALSE]
print(arr)
print(arr)
r = cb["green",,,drop=FALSE]
print(r)
arr = ar["green",,"active"]
r = cb["green",,"active"]
arr
r
all.equal(arr, as.array(r))
arr = ar["green",, c("active","archived","inactive")]
r = cb["green",, c("active","archived","inactive")]
all.equal(arr, as.array(r))
as.data.table(r)
as.data.table(r, na.fill = TRUE)
r
format(aggregate(cb, c("year","status"), sum))
format(capply(cb, c("year","status"), sum))
r = rollup(cb, MARGIN = c("color","year"), FUN = sum)
format(r)
r = rollup(cb, MARGIN = c("color","year"), INDEX = 1:2, FUN = sum)
format(r)
r = capply(cb, c("year","status"), sum)
format(r, dcast = TRUE, formula = year ~ status)
library(rpivotTable)
r = rollup(cb, c("year","status"), FUN = sum, normalize=FALSE)
rpivotTable(r,rows="year", cols=c("status"),width="100%", height="400px")
library(tidyverse)
set.seed(519)
longdata1 <- data.frame(ID = 1:3,
expand.grid(Name = c("Dora", "John", "Rob"), Year = 2012:2014),
BMI = round(runif(9, 18, 35), 0))
longdata1
longdata1
wide = longdata1 %>%
spread(Year, BMI)
wide
longdata2 <- wide %>% gather("2012","2013","2014",key = year,value = BMI)
longdata2
identical(longdata2$BMI, longdata1$BMI)
set.seed(520)
long3 <- data.frame(ID = 1:3,
expand.grid(Name = c("Dora", "John", "Rob"), Year = 2012:2014),
BMI = round(runif(9, 18, 35), 0),
Cholesterol = round(runif(9, 200, 300), 0)
)
long3
wide2
wide2 = long3 %>%
spread(Year, BMI)
wide2
long3 %>%
group_by(ID) %>%
mutate(Visit = 1:n())
1:n()
long3 %>%
group_by(ID) %>%
mutate(Visit = 1:n()) %>%
gather("Year", "BMI", "Cholesterol", key = variable, value = number)
long3 %>%
group_by(ID) %>%
mutate(Visit = 1:n()) %>%
gather("Year", "BMI", "Cholesterol", key = variable, value = number) %>%
unite(combi, variable, Visit)
long3 %>%
group_by(ID) %>%
mutate(Visit = 1:n()) %>%
gather("Year", "BMI", "Cholesterol", key = variable, value = number) %>%
unite(combi, variable, Visit) %>%
spread(combi, number)
library(tidyverse)
library(RNHANES)
library(tableone)
library(labelled)
dat = nhanes_load_data("DEMO_F", "2009-2010") %>%
select(SEQN, RIAGENDR, RIDAGEYR, RIDRETH1) %>%
left_join(nhanes_load_data("DIQ_F", "2009-2010"), by="SEQN") %>%
select(SEQN, RIAGENDR,RIDAGEYR, RIDRETH1, DIQ010) %>%
left_join(nhanes_load_data("BMX_F", "2009-2010"), by="SEQN") %>%
select(SEQN, RIAGENDR,RIDAGEYR, RIDRETH1, DIQ010, BMXBMI ) %>%
left_join(nhanes_load_data("VID_F", "2009-2010"), by="SEQN") %>%
select(SEQN, RIAGENDR,RIDAGEYR, RIDRETH1, DIQ010, BMXBMI, LBXVIDMS) %>%
mutate(gender = recode_factor(RIAGENDR,
`1` = "Males",
`2` = "Females"),
BMI = as.factor(if_else(BMXBMI >= 25, "Overweight", "Normal weight")),
dm = recode_factor(DIQ010,
`1` = "Yes",
`2` = "No"),
race = recode_factor(RIDRETH1,
`1` = "Hispanic",
`2` = "Hispanic",
`3` = "White",
`4` = "Black",
`5` = "Others")) %>%
select(SEQN, RIDAGEYR, LBXVIDMS, gender, BMI, dm, race)
dat %>%
CreateTableOne(vars = select(dat, -SEQN) %>% names(), data = .) %>%
kableone()
dat %>%
CreateTableOne(vars = select(dat, -SEQN) %>% names(), data = .)
var_label(dat) = list(
RIDAGEYR = "Age, years",
BMI = "BMI",
LBXVIDMS = "Vitamin D",
gender = "Females",
dm = "Diabetes ")
print(tab_one, varLabels = TRUE)
vars = select(dat, -SEQN) %>% names(),
test = FALSE,
data = .) -> tab_one
dat %>%
CreateTableOne(
vars = select(dat, -SEQN) %>% names(),
test = FALSE,
data = .) -> tab_one
print(tab_one, varLabels = TRUE)
dat %>%
CreateTableOne(vars = select(dat, -SEQN) %>% names(), data = .) %>%
kableone()
print(tab_one, varLabels = TRUE)
dat %>%
CreateTableOne(vars = select(dat, -SEQN) %>% names(), data = .)
dat %>%
CreateTableOne(
vars = select(dat, -SEQN, -gender) %>% names(),
strata ="gender",
data = .,
test = FALSE) -> tab_one
print(tab_one, varLabels = TRUE)
library("tableone", lib.loc="D:/R/R-3.3.3/library")
install.packages("tableone")
library(tableone)
dat %>%
CreateTableOne(vars = select(dat, -SEQN) %>% names(), data = .) %>%
kableone()
library(tidyverse)
library(RNHANES)
library(labelled)
dat = nhanes_load_data("DEMO_F", "2009-2010") %>%
select(SEQN, RIAGENDR, RIDAGEYR, RIDRETH1) %>%
left_join(nhanes_load_data("DIQ_F", "2009-2010"), by="SEQN") %>%
select(SEQN, RIAGENDR,RIDAGEYR, RIDRETH1, DIQ010) %>%
left_join(nhanes_load_data("BMX_F", "2009-2010"), by="SEQN") %>%
select(SEQN, RIAGENDR,RIDAGEYR, RIDRETH1, DIQ010, BMXBMI ) %>%
left_join(nhanes_load_data("VID_F", "2009-2010"), by="SEQN") %>%
select(SEQN, RIAGENDR,RIDAGEYR, RIDRETH1, DIQ010, BMXBMI, LBXVIDMS) %>%
mutate(gender = recode_factor(RIAGENDR,
`1` = "Males",
`2` = "Females"),
BMI = as.factor(if_else(BMXBMI >= 25, "Overweight", "Normal weight")),
dm = recode_factor(DIQ010,
`1` = "Yes",
`2` = "No"),
race = recode_factor(RIDRETH1,
`1` = "Hispanic",
`2` = "Hispanic",
`3` = "White",
`4` = "Black",
`5` = "Others")) %>%
select(SEQN, RIDAGEYR, LBXVIDMS, gender, BMI, dm, race)
dat %>%
CreateTableOne(vars = select(dat, -SEQN) %>% names(), data = .) %>%
kableone()
left <- data.frame(id=c(2:7),
y2=rnorm(6,100,5))
right <- data.frame(id=rep(1:4,each=2),
z2=sample(letters,8, replace=TRUE))
letters
View(rigth)
View(right)
rnorm(6,100,5)
?rnorm
rnorm(6,100,5)
merge(x=left, y=right, by="id", all.x = TRUE)
merge(x=left, y=right, by="id")
library(sqldf)
mysqldatajoin <- sqldf("select left.*, right.* from left left join right on right.id = left.id")
View(mysqldatajoin)
stackdf1 <- data.frame(both.int=1:4,
expand.factor=c("blue", "yellow"),
mixed.fac.int=factor(letters[1:4]),
date=as.Date("1983-11-22"),
df1only=rep(1:2, each=2),
mixed.fac.chr=I(c("a","b","NA",NA)))
stackdf2 <- data.frame(both.int=5:24,
expand.factor=factor(rep(c(1:4, NA), 4)),
mixed.fac.int=1:4,
date=as.Date("1981-09-24"),
df2only=factor(c("c", "d")),
mixed.fac.chr=c("a","b",NA,"c"))
View(stackdf1)
View(stackdf2)
View(stackdf1)
library(Stack)
install.packages("Stack")
library(Stack)
Stack(stackdf1,stackdf2)
help(package = "Stack")
Stack(left,right)
library(skimr)
install.packages("skimr")
View(choco)
skimr::skim(choco)
md.pattern(BostonHousing)  # pattern or missing values in data.
library(mice)
md.pattern(BostonHousing)  # pattern or missing values in data.
data ("BostonHousing", package="mlbench")
md.pattern(BostonHousing)  # pattern or missing values in data.
original <- BostonHousing  # backup original data
set.seed(100)
BostonHousing[sample(1:nrow(BostonHousing), 40), "rad"] <- NA
BostonHousing[sample(1:nrow(BostonHousing), 40), "ptratio"] = NA
md.pattern(BostonHousing)  # pattern or missing values in data.
head(BostonHousing)
nrow(BostonHousing)
help(package = "Hmisc")
describe(BostonHousing)
Hmisc::describe(BostonHousing)
summary(BostonHousing)
install.packages('MonetDBLite', dependencies = TRUE)
install.packages("https://cran.r-project.org/src/contrib/Archive/MonetDBLite/MonetDBLite_0.6.0.tar.gz",repo = NULL,type = "source")
library(MonetDBLite)
library(DBI)
path.expand("database/")
.Platform$file.sep
getwd()
file.path("./Rfile/201806/0617_combining_data_in_R.R")
file.path("0617_combining_data_in_R.R")
dbdir <- 'database/'
con <- dbConnect(MonetDBLite::MonetDBLite() , dbdir)
monetdb.read.csv(conn = con, files = 'flavors_of_cacao.csv', tablename = 'cacao', header = TRUE, na.strings = '', delim = ',')
dbListTables(con)
dbGetQuery(con, 'SELECT count(*) FROM cacao')
teste <- dbGetQuery(con, "SELECT * FROM cacao LIMIT 100")
View(teste)
library(dplyr)
my_db <- MonetDBLite::src_monetdb(embedded=dbdir)
my_tbl <- tbl(my_db, "cacao")
head(teste)
colnames(cacao)
colnames(teste)
consulta %>% group_by(Review.Date, Broad.Bean.Origin) %>% summarise(mean(Rating))
my_tbl %>% group_by(Review.Date, Broad.Bean.Origin) %>% summarise(mean(Rating))
my_tbl %>% group_by(Review.Date, Broad.Bean.Origin) %>% summarise(mean(Rating)) -> consulta
consulta <- collect(consulta)
View(consulta)
library(tuneR)
install.packages("tuneR")
library(tuneR)
path.expand("~")
originalSound <- readWave("~/model_data/G-scale.wav")
play(originalSound) # opens Windows Media Player to play the sound. Beware that the window does not automatically close when the audio file is finished playing. You need to close the window before you can continue in R.
play(originalSound) # opens Windows Media Player to play the sound. Beware that the window does not automatically close when the audio file is finished playing. You need to close the window before you can continue in R.
library(tuneR)
scaleNotesFreqs<- c(NA, NA, NA, 196.00, 196.00, NA, 220.0, NA, NA, 246.9, NA, 261.6, 261.6, NA, 293.7, 293.7, NA, 329.6, 329.6, NA, 370.0, 370.0, NA, 392.0, NA)
scaleNotes <- noteFromFF(scaleNotesFreqs)
scaleNotes
transcribeMusic <- function(wavFile, widthSample = 4096, expNotes = NULL) {
#See details about the wavFile, plot it, and/or play it
#summary(wavFile)
plot(wavFile)
perioWav <- periodogram(wavFile, width = widthSample)
freqWav <- FF(perioWav)
noteWav <- noteFromFF(freqWav)
melodyplot(perioWav, observed = noteWav,
expected = expNotes, plotenergy = FALSE,
main = Sys.Date())
#Print out notes names
noteWavNames <- noteWav[!is.na(noteWav)]
noteWavNames <- noteWavNames[1:21] # I limited the number of notes to 21 here - because that is the number of notes extracted from the G-Scale.wav file and to make comparisons later I need the extractions to be of the same length.
print(noteWavNames)
print(notenames(noteWavNames))
return(noteWavNames)
}
transcribeMusic(originalSound, expNotes = scaleNotes)
plot(originalSound)
periodogram(originalSound, width = 4096)
FF(periodogram(originalSound, width = 4096))
install.packages("audio")
library(audio)
list.files()
audiorec <- function(kk,f){  # kk: time length in seconds; f: filename
if(f %in% list.files())
{file.remove(f); print('The former file has been replaced');}
require(audio)
s11 <- rep(NA_real_, 16000*kk) # Samplingrate=16000
message("5 seconds..") # Counting down 5 seconds befor the recording starts
for (i in c(5:1)){
message(i)
Sys.sleep(1)
}
message("Recording starts now...")
record(s11, 16000, 1)  # record in mono mode
wait(kk)
save.wave(s11,f)
.rs.restartR() # As mentioned in the above cited post: recording with the audio package works once, but for some reason it will not continue to work afterwards unless the R session is restarted. For this reason I included a restart in this function. I am hoping to find a more elegant solution one day soon.
}
summary(originalSound)
date
filename
temp_date = gsub(":","-",as.character(Sys.time()))
temp_filename = paste0(temp_date,"_recording.wav")
audiorec(6.3, temp_filename)
testSound <- readWave(temp_filename)
tuneR::play(testSound)
results <- transcribeMusic(testSound, expNotes = scaleNotes)
expected_notes <- c(-14,-14,-14,-12,-12,-10,-10,-9,-9,-9,-7,-7,-7,-5,-5,-5,-3,-3,-3,-2,-2)
expected_notenames <- notenames(expected_notes)
expected_notenames
results
updatePerformance <- function(results){
files <- list.files()
if (("performance.csv" %in% files) == FALSE){
message("No performance csv existing yet - creating it now...")
dat <- as.data.frame(results)
names(dat) <- "noteWavNames"
dat$notenames <- notenames(results)
dat$expected <- expected_notes
dat$expected_notenames <- expected_notenames
dat$date <- as.character(Sys.Date())
dat$rownum <- row.names(dat)
dat$session <- 1 # every recording gets a unique session ID
performance <- dat
write.csv2(performance, "performance.csv", row.names = FALSE)
print("Done!")
return(performance)
} else {
performance <- read.csv2("performance.csv", stringsAsFactors = FALSE)
dat <- as.data.frame(results)
names(dat) <- "noteWavNames"
dat$notenames <- notenames(results)
dat$expected <- expected_notes
dat$expected_notenames <- expected_notenames
dat$date <- as.character(Sys.Date())
dat$rownum <- row.names(dat)
session_id <- performance[nrow(performance),"session"] + 1
dat$session <- session_id
performance <- rbind(performance, dat)
write.csv2(performance, "performance.csv", row.names = FALSE)
print("Done!")
return(performance)
}
}
performance <- updatePerformance(results)
plot(performance$noteWavNames, type = "l", col = "red") # the red line shows what I played
lines(performance$expected,col="green") # the green line shows what was expected
performance$expected
lines(performance$expected,col="green") # the green line shows what was expected
temp_date = gsub(":","-",as.character(Sys.time()))
temp_filename = paste0(temp_date,"_recording.wav")
audiorec(6.3, temp_filename)
testSound <- readWave(temp_filename)
tuneR::play(testSound)
results <- transcribeMusic(testSound, expNotes = scaleNotes)
expected_notes <- c(-14,-14,-14,-12,-12,-10,-10,-9,-9,-9,-7,-7,-7,-5,-5,-5,-3,-3,-3,-2,-2)
expected_notenames <- notenames(expected_notes)
performance <- updatePerformance(results)
plot(performance$noteWavNames, type = "l", col = "red") # the red line shows what I played
lines(performance$expected,col="green") # the green line shows what was expected
plotProgress <- function(performance, by){ # we can pass in the performance df and define the variable by which we want to calculate the accuracy (MSE)
progress <- c()
for (i in unique(performance[,by])){
print(i)
dat <- performance[performance[,by] == i,]
dat$res <- dat$expected-dat$noteWavNames
mse <- mean(dat$res^2)
print(mse)
progress <- c(progress,mse*-1) # To make the visualizations of the MSE a bit more intuitive to read - I am converting them from positive to negative numbers (So when a value is closer to 0, the line goes up instead of down.)
}
plot(progress, type = "l", yaxt="n", xaxt="n",ylim = c(min(progress),0), lwd = 2, col = "tomato", xlab = by, ylab = "accuracy", main = paste0("G-Scale Accuracy (",unique(performance$date[performance$session == min(performance$session)])," - ", unique(performance$date[performance$session == max(performance$session)]),")"))
axis(2, at = 0, labels="100%", las=2)
axis(1, at = c(1:length(unique(performance[,by]))),labels = unique(performance[,by]))
return(progress)
}
plotProgress(performance, by = "session")
plotProgress(performance, by = "date")
plotProgress(performance[performance$expected_notenames != "g",], by = "expected_notenames") # The G is often the most "off" note as it is the first and the last one and suffers the most from noise/irregularities. I decided to filter it out so the other notes can be inspected more properly. I can see the E is my most accurate note.
progress <- plotProgress(performance, by = "session")
library(ggplot2)
progress <- as.data.frame(progress)
progress$id <- unique(performance$session)
ggplot(progress, aes(id,progress)) +
geom_point() +
geom_smooth() +
ggtitle(paste0("G-Scale Accuracy (",unique(performance$date[performance$session == min(performance$session)])," - ", unique(performance$date[performance$session == max(performance$session)]),")"))+
ylab("Accuracy (0 = 100% accurate)") +
xlab("Session")
install.packages("googlesheets")
library(googlesheets)
gs_auth(new_user = TRUE)
gs_auth(new_user = TRUE)
gs_auth(new_user = TRUE)
.rs.restartR()
library(googlesheets)
gs_auth(new_user = TRUE)
gs_auth(new_user = TRUE)
.rs.restartR()
library(googlesheets)
gs_auth(new_user = TRUE)
gs_auth(new_user = TRUE)
gs_ls()
gs_ls()
library(googlesheets)
R.version
proxy_url <- "http://127.0.0.1:50837/" #Psiphon 3
Sys.setenv(http_proxy = proxy_url, https_proxy = proxy_url, ftp_proxy = proxy_url)
gs_auth(new_user = TRUE)
gs_ls()
gs_ls()
for_gs <- gs_title("googlesheets_test")
for_gs <- gs_title("go")
for_gs <- gs_title("go~")
for_gs <- gs_title("googlesheet_test")
for_gs_sheet <- gs_read(for_gs)
str(for_gs_sheet)
gs_edit_cells(for_gs, ws = "Sheet1", anchor = "A2", input = c(1,2), byrow = TRUE)
str(for_gs)
gs_new(title = "mtcars", ws_title = "first_sheet", input = mtcars)
options()
options$browser
options()$browser
.rs.isBrowserActive()
library(googlesheets)
options(browser = "C:/Program Files (x86)/Google/Chrome/Application/chrome.exe")
proxy_url <- "http://127.0.0.1:50837/" #Psiphon 3
Sys.setenv(http_proxy = proxy_url, https_proxy = proxy_url, ftp_proxy = proxy_url)
gs_auth(new_user = TRUE)
