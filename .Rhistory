library(rlist)
library(jsonlite)
library(dplyr)
resp<-GET("https://reqres.in/api/users?pageid=2")
http_type(resp)  #. This method will tell us what is the type of response fetched from GET() call to the API.
resp
resp$content
http_error(resp)
?GET
query = list(page = "2")
resp = GET("https://reqres.in/api/users",query = query)
http_type(resp)
resp
http_error(resp)
jsonRespText = content(resp,as = "text")
jsonRespText
jsonRespParsed = content(resp,as = "parsed")
jsonRespParsed
jsonliteparsed = fromJSON(jsonRespText)
jsonliteparsed
modJson<-jsonRespParsed$data #. Access data element of whole list and ignore other vectors
modJson
View(modJson)
type(modJson)
typeof(modJson)
class(modJson)
str(modJson)
json_df = modJson%>%bind_rows%>%select(id,first_name,last_name,avatar)
View(json_df)
rlistContent = list.select(modJson,id,last_name)
rlistContent
rlistStack = list.stack(modJson)
View(rlistStack)
post_result <- POST(url="http://httpbin.org/post",body="this is a test") # where body argument accpets data we wish to send to server
post_result
?jsonlite::fromJSON
nominatim_osm <- function(address = NULL)
{
if(suppressWarnings(is.null(address)))
return(data.frame())
tryCatch(
d <- jsonlite::fromJSON(
gsub('\\@addr\\@', gsub('\\s+', '\\%20', address),
'http://nominatim.openstreetmap.org/search/@addr@?format=json&addressdetails=0&limit=1')
), error = function(c) return(data.frame())
)
if(length(d) == 0) return(data.frame())
return(data.frame(lon = as.numeric(d$lon), lat = as.numeric(d$lat)))
}
suppressPackageStartupMessages(library(dplyr))
addresses <- c("Baker Street 221b, London", "Brandenburger Tor, Berlin",
"Platz der Deutschen Einheit 1, Hamburg", "Arc de Triomphe de l’Etoile, Paris",
"Дворцовая пл., Санкт-Петербург, Россия")
d <- suppressWarnings(lapply(addresses, function(address) {
#set the elapsed time counter to 0
t <- Sys.time()
#calling the nominatim OSM API
api_output <- nominatim_osm(address)
#get the elapsed time
t <- difftime(Sys.time(), t, 'secs')
#return data.frame with the input address, output of the nominatim_osm function and elapsed time
return(data.frame(address = address, api_output, elapsed_time = t))
}) %>%
#stack the list output into data.frame
bind_rows() %>% data.frame())
d
d <- suppressWarnings(lapply(addresses, function(address) {
#set the elapsed time counter to 0
t <- Sys.time()
#calling the nominatim OSM API
api_output <- nominatim_osm(address)
#get the elapsed time
t <- difftime(Sys.time(), t, 'secs')
#return data.frame with the input address, output of the nominatim_osm function and elapsed time
return(data.frame(address = address, api_output, elapsed_time = t))
})
)
d = nominatim_osm("Baker Street 221b, London")
View(d)
d = nominatim_osm("Brandenburger Tor, Berlin")
d = nominatim_osm("北京天安门")
d = nominatim_osm("tiananmen,beijing")
d = nominatim_osm("Дворцовая пл., Санкт-Петербург, Россия")
d = nominatim_osm("Arc de Triomphe de l’Etoile, Paris")
View(d)
d = nominatim_osm("Platz der Deutschen Einheit 1, Hamburg")
addresses <- c("Baker Street 221b, London", "Brandenburger Tor, Berlin",
"Platz der Deutschen Einheit 1, Hamburg")
d <- suppressWarnings(lapply(addresses, function(address) {
#set the elapsed time counter to 0
t <- Sys.time()
#calling the nominatim OSM API
api_output <- nominatim_osm(address)
#get the elapsed time
t <- difftime(Sys.time(), t, 'secs')
#return data.frame with the input address, output of the nominatim_osm function and elapsed time
return(data.frame(address = address, api_output, elapsed_time = t))
}) %>%
#stack the list output into data.frame
bind_rows() %>% data.frame())
gsub('\\@addr\\@', gsub('\\s+', '\\%20', "Baker Street 221b, London"),
'http://nominatim.openstreetmap.org/search/@addr@?format=json&addressdetails=0&limit=1')
library(tabulizer)
library(dplyr)
location <- 'http://www.edd.ca.gov/jobs_and_training/warn/WARN-Report-for-7-1-2016-to-10-25-2016.pdf'
out <- extract_tables(location)
path.expand(".")
path.expand("~")
getwd()
out = extract_tables("~/model_data/warn_report.pdf")
final <- do.call(rbind, out[-length(out)])
View(final)
headers <- c('Notice.Date', 'Effective.Date', 'Received.Date', 'Company', 'City',
'No.of.Employees', 'Layoff/Closure')
View(final)
View(final[2:nrow(final),])
names(final) <- headers
head(final)
final <- as.data.frame(final[2:nrow(final), ])
final <- do.call(rbind, out[-length(out)])
final <- as.data.frame(final[2:nrow(final), ])
View(final)
names(final) <- headers
head(final)
final <- final %>%
# Convert date columns to date objects
mutate_each(funs(as.Date(., format='%m/%d/%Y')), Notice.Date, Effective.Date, Received.Date) %>%
# Convert No.of.Employees to numeric
mutate(No.of.Employees = as.numeric(levels(No.of.Employees)[No.of.Employees]))
final <- final %>%
# Convert date columns to date objects
mutate_at(funs(as.Date(., format='%m/%d/%Y')), Notice.Date, Effective.Date, Received.Date) %>%
# Convert No.of.Employees to numeric
mutate(No.of.Employees = as.numeric(levels(No.of.Employees)[No.of.Employees]))
rlang::last_error()
final <- final %>%
# Convert No.of.Employees to numeric
mutate(No.of.Employees = as.numeric(levels(No.of.Employees)[No.of.Employees]))
View(final)
headers <- c('Notice.Date', 'Effective.Date', 'Received.Date', 'Company', 'City', 'County',
'No.of.Employees', 'Layoff/Closure')
names(final) <- headers
head(final)
final <- final %>%
# Convert date columns to date objects
mutate_each(funs(as.Date(., format='%m/%d/%Y')), Notice.Date, Effective.Date, Received.Date) %>%
# Convert No.of.Employees to numeric
mutate(No.of.Employees = as.numeric(levels(No.of.Employees)[No.of.Employees]))
getwd()
write.csv(final, file='result_data/CA_WARN.csv', row.names=FALSE)
library(tidyverse)
dat = data.frame(
id = c(1,1,1,1, 2,2,2,2, 3,3,3,3),
quarter = rep(c("Jan", "Apr", "Jul", "Oct"), times=3),
spending = c(22,35,10,64, 55,23,NA,10, 42,NA,NA,18)
)
dat
dat %>% group_by(id) %>%
summarise(missing=sum(is.na(spending)))
na.omit(dat)
dat %>%
group_by(id) %>%
mutate(spending_mean = ifelse(is.na(spending), mean(spending, na.rm=T), spending))
dat_fill_down = dat %>%
group_by(id) %>%
fill(spending, .direction = c("down"))
dat_fill_up = dat %>%
group_by(id) %>%
fill(spending, .direction = c("up"))
# Management accounting & controlling
library(finstr)
# Data tables
library(knitr)
library(kableExtra)
library(flextable)
library(htmlTable)
library(htmlwidgets)
library(DT)
library(xlsx)
# Data management
library(skimr)
library(dplyr)
library(tidyverse)
library(lubridate)
# Visualization
library(ggplot2)
library(waterfalls)
library(plotly)
install.packages("finstr")
githubinstall::githubinstall("finstr")
df <- read.table(textConnection("1|a,b,c\n2|a,c\n3|b,d\n4|e,f"), header = F, sep = "|", stringsAsFactors = F)
View(df)
s <- strsplit(df$V2, split = ",")
s
data.frame(V1 = rep(df$V1, sapply(s, length)), V2 = unlist(s))
separate_rows(df, V2) in tidyr
library(tidyr)
separate_rows(df, V2)
rep(c("A","B","C","D","E")
)
df1 <- data.frame(first = rep(c("A","B","C","D","E")), second = rep(c(1,2),each=5),
third = rnorm(10))
View(df1)
dcast(df1, first ~ second, value.var="third")
?decast
?dcast
df = matrix(nrow = 3,ncol = 3)
df = data.frame(df)
View(df)
View(df)
df = data.frame(df)
View(df)
system("R CMD SHLIB calc_tstat.c")
df = matrix(nrow = 3,ncol = 3)
library(plyr)
alply(df,1)
library(AUC)
data(churn)
test_roc = roc(churn$predictions,churn$labels)
test_auc = auc(test_roc)
churn$predictions
rstudioapi::getActiveDocumentContext()$path
dirname(rstudioapi::getActiveDocumentContext()$path)
?rstudioapi::getActiveDocumentContext
getSourceEditorContext()
library(rstudioapi)
temp = dirname(rstudioapi::getActiveDocumentContext()$path)
temp
getConsoleEditorContext(rstudioaps)
getConsoleEditorContext()
getActiveDocumentContext()
getSourceEditorContext()
getSrcDirectory(getGeoData)
library(data.table)
library(data.cube)
install.packages("data.cube")
library(githubinstall)
githubinstall("data.cube")
install.packages("rpivotTable")
set.seed(1L)
ar.dimnames = list(color = sort(c("green","yellow","red")),
year = as.character(2011:2015),
status = sort(c("active","inactive","archived","removed")))
ar.dim = sapply(ar.dimnames, length)
ar.dim
sample(c(rep(NA, 4), 4:7/2), prod(ar.dim), TRUE)
c(rep(NA, 4), 4:7/2)
prod(ar.dim)
ar = array(sample(c(rep(NA, 4), 4:7/2), prod(ar.dim), TRUE),
unname(ar.dim),
ar.dimnames)
ar
cb = as.cube(ar)
library(data.cube)
library(rpivotTable)
cb = as.cube(ar)
print(cb)
str(cb)
all.equal(ar, as.array(cb))
all.equal(dim(ar), dim(cb))
all.equal(dimnames(ar), dimnames(cb))
arr = ar["green",,]
print(arr)
r = cb["green",]
print(r)
arr = ar["green",,,drop=FALSE]
print(arr)
print(arr)
r = cb["green",,,drop=FALSE]
print(r)
arr = ar["green",,"active"]
r = cb["green",,"active"]
arr
r
all.equal(arr, as.array(r))
arr = ar["green",, c("active","archived","inactive")]
r = cb["green",, c("active","archived","inactive")]
all.equal(arr, as.array(r))
as.data.table(r)
as.data.table(r, na.fill = TRUE)
r
format(aggregate(cb, c("year","status"), sum))
format(capply(cb, c("year","status"), sum))
r = rollup(cb, MARGIN = c("color","year"), FUN = sum)
format(r)
r = rollup(cb, MARGIN = c("color","year"), INDEX = 1:2, FUN = sum)
format(r)
r = capply(cb, c("year","status"), sum)
format(r, dcast = TRUE, formula = year ~ status)
library(rpivotTable)
r = rollup(cb, c("year","status"), FUN = sum, normalize=FALSE)
rpivotTable(r,rows="year", cols=c("status"),width="100%", height="400px")
library(tidyverse)
set.seed(519)
longdata1 <- data.frame(ID = 1:3,
expand.grid(Name = c("Dora", "John", "Rob"), Year = 2012:2014),
BMI = round(runif(9, 18, 35), 0))
longdata1
longdata1
wide = longdata1 %>%
spread(Year, BMI)
wide
longdata2 <- wide %>% gather("2012","2013","2014",key = year,value = BMI)
longdata2
identical(longdata2$BMI, longdata1$BMI)
set.seed(520)
long3 <- data.frame(ID = 1:3,
expand.grid(Name = c("Dora", "John", "Rob"), Year = 2012:2014),
BMI = round(runif(9, 18, 35), 0),
Cholesterol = round(runif(9, 200, 300), 0)
)
long3
wide2
wide2 = long3 %>%
spread(Year, BMI)
wide2
long3 %>%
group_by(ID) %>%
mutate(Visit = 1:n())
1:n()
long3 %>%
group_by(ID) %>%
mutate(Visit = 1:n()) %>%
gather("Year", "BMI", "Cholesterol", key = variable, value = number)
long3 %>%
group_by(ID) %>%
mutate(Visit = 1:n()) %>%
gather("Year", "BMI", "Cholesterol", key = variable, value = number) %>%
unite(combi, variable, Visit)
long3 %>%
group_by(ID) %>%
mutate(Visit = 1:n()) %>%
gather("Year", "BMI", "Cholesterol", key = variable, value = number) %>%
unite(combi, variable, Visit) %>%
spread(combi, number)
library(tidyverse)
library(RNHANES)
library(tableone)
library(labelled)
dat = nhanes_load_data("DEMO_F", "2009-2010") %>%
select(SEQN, RIAGENDR, RIDAGEYR, RIDRETH1) %>%
left_join(nhanes_load_data("DIQ_F", "2009-2010"), by="SEQN") %>%
select(SEQN, RIAGENDR,RIDAGEYR, RIDRETH1, DIQ010) %>%
left_join(nhanes_load_data("BMX_F", "2009-2010"), by="SEQN") %>%
select(SEQN, RIAGENDR,RIDAGEYR, RIDRETH1, DIQ010, BMXBMI ) %>%
left_join(nhanes_load_data("VID_F", "2009-2010"), by="SEQN") %>%
select(SEQN, RIAGENDR,RIDAGEYR, RIDRETH1, DIQ010, BMXBMI, LBXVIDMS) %>%
mutate(gender = recode_factor(RIAGENDR,
`1` = "Males",
`2` = "Females"),
BMI = as.factor(if_else(BMXBMI >= 25, "Overweight", "Normal weight")),
dm = recode_factor(DIQ010,
`1` = "Yes",
`2` = "No"),
race = recode_factor(RIDRETH1,
`1` = "Hispanic",
`2` = "Hispanic",
`3` = "White",
`4` = "Black",
`5` = "Others")) %>%
select(SEQN, RIDAGEYR, LBXVIDMS, gender, BMI, dm, race)
dat %>%
CreateTableOne(vars = select(dat, -SEQN) %>% names(), data = .) %>%
kableone()
dat %>%
CreateTableOne(vars = select(dat, -SEQN) %>% names(), data = .)
var_label(dat) = list(
RIDAGEYR = "Age, years",
BMI = "BMI",
LBXVIDMS = "Vitamin D",
gender = "Females",
dm = "Diabetes ")
print(tab_one, varLabels = TRUE)
vars = select(dat, -SEQN) %>% names(),
test = FALSE,
data = .) -> tab_one
dat %>%
CreateTableOne(
vars = select(dat, -SEQN) %>% names(),
test = FALSE,
data = .) -> tab_one
print(tab_one, varLabels = TRUE)
dat %>%
CreateTableOne(vars = select(dat, -SEQN) %>% names(), data = .) %>%
kableone()
print(tab_one, varLabels = TRUE)
dat %>%
CreateTableOne(vars = select(dat, -SEQN) %>% names(), data = .)
dat %>%
CreateTableOne(
vars = select(dat, -SEQN, -gender) %>% names(),
strata ="gender",
data = .,
test = FALSE) -> tab_one
print(tab_one, varLabels = TRUE)
library("tableone", lib.loc="D:/R/R-3.3.3/library")
install.packages("tableone")
library(tableone)
dat %>%
CreateTableOne(vars = select(dat, -SEQN) %>% names(), data = .) %>%
kableone()
library(tidyverse)
library(RNHANES)
library(labelled)
dat = nhanes_load_data("DEMO_F", "2009-2010") %>%
select(SEQN, RIAGENDR, RIDAGEYR, RIDRETH1) %>%
left_join(nhanes_load_data("DIQ_F", "2009-2010"), by="SEQN") %>%
select(SEQN, RIAGENDR,RIDAGEYR, RIDRETH1, DIQ010) %>%
left_join(nhanes_load_data("BMX_F", "2009-2010"), by="SEQN") %>%
select(SEQN, RIAGENDR,RIDAGEYR, RIDRETH1, DIQ010, BMXBMI ) %>%
left_join(nhanes_load_data("VID_F", "2009-2010"), by="SEQN") %>%
select(SEQN, RIAGENDR,RIDAGEYR, RIDRETH1, DIQ010, BMXBMI, LBXVIDMS) %>%
mutate(gender = recode_factor(RIAGENDR,
`1` = "Males",
`2` = "Females"),
BMI = as.factor(if_else(BMXBMI >= 25, "Overweight", "Normal weight")),
dm = recode_factor(DIQ010,
`1` = "Yes",
`2` = "No"),
race = recode_factor(RIDRETH1,
`1` = "Hispanic",
`2` = "Hispanic",
`3` = "White",
`4` = "Black",
`5` = "Others")) %>%
select(SEQN, RIDAGEYR, LBXVIDMS, gender, BMI, dm, race)
dat %>%
CreateTableOne(vars = select(dat, -SEQN) %>% names(), data = .) %>%
kableone()
left <- data.frame(id=c(2:7),
y2=rnorm(6,100,5))
right <- data.frame(id=rep(1:4,each=2),
z2=sample(letters,8, replace=TRUE))
letters
View(rigth)
View(right)
rnorm(6,100,5)
?rnorm
rnorm(6,100,5)
merge(x=left, y=right, by="id", all.x = TRUE)
merge(x=left, y=right, by="id")
library(sqldf)
mysqldatajoin <- sqldf("select left.*, right.* from left left join right on right.id = left.id")
View(mysqldatajoin)
stackdf1 <- data.frame(both.int=1:4,
expand.factor=c("blue", "yellow"),
mixed.fac.int=factor(letters[1:4]),
date=as.Date("1983-11-22"),
df1only=rep(1:2, each=2),
mixed.fac.chr=I(c("a","b","NA",NA)))
stackdf2 <- data.frame(both.int=5:24,
expand.factor=factor(rep(c(1:4, NA), 4)),
mixed.fac.int=1:4,
date=as.Date("1981-09-24"),
df2only=factor(c("c", "d")),
mixed.fac.chr=c("a","b",NA,"c"))
View(stackdf1)
View(stackdf2)
View(stackdf1)
library(Stack)
install.packages("Stack")
library(Stack)
Stack(stackdf1,stackdf2)
help(package = "Stack")
Stack(left,right)
library(skimr)
install.packages("skimr")
View(choco)
skimr::skim(choco)
md.pattern(BostonHousing)  # pattern or missing values in data.
library(mice)
md.pattern(BostonHousing)  # pattern or missing values in data.
data ("BostonHousing", package="mlbench")
md.pattern(BostonHousing)  # pattern or missing values in data.
original <- BostonHousing  # backup original data
set.seed(100)
BostonHousing[sample(1:nrow(BostonHousing), 40), "rad"] <- NA
BostonHousing[sample(1:nrow(BostonHousing), 40), "ptratio"] = NA
md.pattern(BostonHousing)  # pattern or missing values in data.
head(BostonHousing)
nrow(BostonHousing)
help(package = "Hmisc")
describe(BostonHousing)
Hmisc::describe(BostonHousing)
summary(BostonHousing)
install.packages('MonetDBLite', dependencies = TRUE)
install.packages("https://cran.r-project.org/src/contrib/Archive/MonetDBLite/MonetDBLite_0.6.0.tar.gz",repo = NULL,type = "source")
library(MonetDBLite)
library(DBI)
path.expand("database/")
.Platform$file.sep
getwd()
file.path("./Rfile/201806/0617_combining_data_in_R.R")
file.path("0617_combining_data_in_R.R")
dbdir <- 'database/'
con <- dbConnect(MonetDBLite::MonetDBLite() , dbdir)
monetdb.read.csv(conn = con, files = 'flavors_of_cacao.csv', tablename = 'cacao', header = TRUE, na.strings = '', delim = ',')
dbListTables(con)
dbGetQuery(con, 'SELECT count(*) FROM cacao')
teste <- dbGetQuery(con, "SELECT * FROM cacao LIMIT 100")
View(teste)
library(dplyr)
my_db <- MonetDBLite::src_monetdb(embedded=dbdir)
my_tbl <- tbl(my_db, "cacao")
head(teste)
colnames(cacao)
colnames(teste)
consulta %>% group_by(Review.Date, Broad.Bean.Origin) %>% summarise(mean(Rating))
my_tbl %>% group_by(Review.Date, Broad.Bean.Origin) %>% summarise(mean(Rating))
my_tbl %>% group_by(Review.Date, Broad.Bean.Origin) %>% summarise(mean(Rating)) -> consulta
consulta <- collect(consulta)
View(consulta)
